{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение лемматизаторов \n",
    "\n",
    "\"Стандарты\" были взяты из https://drive.google.com/drive/folders/0B600DBw1ZmZAd3lhNHQ1MUVoRkk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import pymorphy2\n",
    "from pymystem3 import Mystem\n",
    "import maru\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import glob\n",
    "from nltk import word_tokenize\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ru_stop = stopwords.words('russian')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравниваются лемматизаторы:\n",
    "* WordNetLemmatizer\n",
    "* pymorphy2\n",
    "* Mystem\n",
    "* maru c rnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "mystem = Mystem() \n",
    "analyzer = maru.get_analyzer(tagger='rnn', lemmatizer='pymorphy')\n",
    "\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text.lower().strip())\n",
    "    return ''.join(text)\n",
    "    \n",
    "def wordnet_lemmatize(text):\n",
    "    return wnl.lemmatize(text)\n",
    "\n",
    "def pymorphy_lemmatize(text):\n",
    "\n",
    "    return morph.parse(text)[0].normal_form\n",
    "def mystem_lemmatize(text):\n",
    "\n",
    "    return mystem.lemmatize(text)[0]\n",
    "def mystem_lemmatize_sents(text):\n",
    "    #mystem=Mystem()\n",
    "    text=''.join(mystem.lemmatize(text))\n",
    "    text=word_tokenize(text)\n",
    "    return text\n",
    "def maru_rnn_lemmatize(x):\n",
    "    analyzed = analyzer.analyze([x]) \n",
    "    for i in analyzed:\n",
    "        obj = i\n",
    "    return obj.lemma\n",
    "\n",
    "def evalute(gold_standart, prepared_text):\n",
    "    \n",
    "    return sum(gold_standart==prepared_text) / len(gold_standart)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все стандарты соединены в один, удалены все знаки пуктуации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19560, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['index', 'text', 'standart_text', 'col1', 'col2']\n",
    "standart = []\n",
    "files = glob.glob('/proj_news_viz/data/*.txt')\n",
    "for file in files:\n",
    "    standart.append(pd.read_csv(file, sep = '\\t', header=None, names = columns))\n",
    "standart = pd.concat(standart, ignore_index=True)\n",
    "standart = standart[['text', 'standart_text']]  \n",
    "standart.shape         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "standart = standart.drop(standart[standart.text.apply(lambda x: x.isalpha()==False)].index)\n",
    "standart = standart.reset_index()\n",
    "standart['tokenized_text'] = standart.text.apply(lambda x: tokenize(x))\n",
    "standart['standart_text'] = standart.standart_text.apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение лемматизаторов и времени выполнения: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maru_rnn_lemmatize accuracy: 0.919\n",
      "Running time: 92 seconds\n",
      "wordnet_lemmatize accuracy: 0.478\n",
      "Running time: 0 seconds\n",
      "pymorphy_lemmatize accuracy: 0.908\n",
      "Running time: 1 seconds\n",
      "mystem_lemmatize accuracy: 0.863\n",
      "Running time: 2 seconds\n"
     ]
    }
   ],
   "source": [
    "lemmatizers = [maru_rnn_lemmatize, wordnet_lemmatize, pymorphy_lemmatize, mystem_lemmatize]\n",
    "for fun in lemmatizers:\n",
    "    start = np.datetime64('now')\n",
    "    standart[fun.__name__] = standart.tokenized_text.apply(lambda x: fun(x))\n",
    "    print(f'{fun.__name__}' + \n",
    "          f' accuracy: {np.round(evalute(standart.standart_text, \n",
    "                                         standart[fun.__name__]),3)}')\n",
    "    print(f'Running time: {str(np.datetime64(\"now\") - start)}')                            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mystem_lemmatize_sents accuracy: 0.878\n",
      "Running time: 2 seconds\n"
     ]
    }
   ],
   "source": [
    "start = np.datetime64('now')\n",
    "standart['mystem_lemmatize_sents'] = pd.Series(mystem_lemmatize_sents(\" \".join(standart.text)))\n",
    "print('mystem_lemmatize_sents' +\n",
    "      f' accuracy: {np.round(evalute(standart.standart_text,\n",
    "                                     standart[\"mystem_lemmatize_sents\"]),3)}')\n",
    "print(f'Running time: {str(np.datetime64(\"now\") - start)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример предложения, обработанного разными лемматизаторами: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>standart_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>maru_rnn_lemmatize</th>\n",
       "      <th>wordnet_lemmatize</th>\n",
       "      <th>pymorphy_lemmatize</th>\n",
       "      <th>mystem_lemmatize</th>\n",
       "      <th>mystem_lemmatize_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2573</td>\n",
       "      <td>Но</td>\n",
       "      <td>но</td>\n",
       "      <td>но</td>\n",
       "      <td>но</td>\n",
       "      <td>но</td>\n",
       "      <td>но</td>\n",
       "      <td>но</td>\n",
       "      <td>но</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2574</td>\n",
       "      <td>самым</td>\n",
       "      <td>самый</td>\n",
       "      <td>самым</td>\n",
       "      <td>самый</td>\n",
       "      <td>самым</td>\n",
       "      <td>самый</td>\n",
       "      <td>самый</td>\n",
       "      <td>самый</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2575</td>\n",
       "      <td>надежным</td>\n",
       "      <td>надёжный</td>\n",
       "      <td>надежным</td>\n",
       "      <td>надёжный</td>\n",
       "      <td>надежным</td>\n",
       "      <td>надёжный</td>\n",
       "      <td>надежный</td>\n",
       "      <td>надежный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2576</td>\n",
       "      <td>способом</td>\n",
       "      <td>способ</td>\n",
       "      <td>способом</td>\n",
       "      <td>способ</td>\n",
       "      <td>способом</td>\n",
       "      <td>способ</td>\n",
       "      <td>способ</td>\n",
       "      <td>способ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2577</td>\n",
       "      <td>пустить</td>\n",
       "      <td>пустить</td>\n",
       "      <td>пустить</td>\n",
       "      <td>пустить</td>\n",
       "      <td>пустить</td>\n",
       "      <td>пустить</td>\n",
       "      <td>пускать</td>\n",
       "      <td>пускать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2578</td>\n",
       "      <td>под</td>\n",
       "      <td>под</td>\n",
       "      <td>под</td>\n",
       "      <td>под</td>\n",
       "      <td>под</td>\n",
       "      <td>под</td>\n",
       "      <td>под</td>\n",
       "      <td>под</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2579</td>\n",
       "      <td>откос</td>\n",
       "      <td>откос</td>\n",
       "      <td>откос</td>\n",
       "      <td>откос</td>\n",
       "      <td>откос</td>\n",
       "      <td>откос</td>\n",
       "      <td>откос</td>\n",
       "      <td>откос</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2580</td>\n",
       "      <td>дневной</td>\n",
       "      <td>дневной</td>\n",
       "      <td>дневной</td>\n",
       "      <td>дневной</td>\n",
       "      <td>дневной</td>\n",
       "      <td>дневный</td>\n",
       "      <td>дневной</td>\n",
       "      <td>дневной</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2581</td>\n",
       "      <td>распорядок</td>\n",
       "      <td>распорядок</td>\n",
       "      <td>распорядок</td>\n",
       "      <td>распорядок</td>\n",
       "      <td>распорядок</td>\n",
       "      <td>распорядок</td>\n",
       "      <td>распорядок</td>\n",
       "      <td>распорядок</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>2582</td>\n",
       "      <td>было</td>\n",
       "      <td>быть</td>\n",
       "      <td>было</td>\n",
       "      <td>быть</td>\n",
       "      <td>было</td>\n",
       "      <td>быть</td>\n",
       "      <td>быть</td>\n",
       "      <td>быть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>2583</td>\n",
       "      <td>превратить</td>\n",
       "      <td>превратить</td>\n",
       "      <td>превратить</td>\n",
       "      <td>превратить</td>\n",
       "      <td>превратить</td>\n",
       "      <td>превратить</td>\n",
       "      <td>превращать</td>\n",
       "      <td>превращать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>2584</td>\n",
       "      <td>утреннюю</td>\n",
       "      <td>утренний</td>\n",
       "      <td>утреннюю</td>\n",
       "      <td>утренний</td>\n",
       "      <td>утреннюю</td>\n",
       "      <td>утренний</td>\n",
       "      <td>утренний</td>\n",
       "      <td>утренний</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2585</td>\n",
       "      <td>прогулку</td>\n",
       "      <td>прогулка</td>\n",
       "      <td>прогулку</td>\n",
       "      <td>прогулка</td>\n",
       "      <td>прогулку</td>\n",
       "      <td>прогулка</td>\n",
       "      <td>прогулка</td>\n",
       "      <td>прогулка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>2586</td>\n",
       "      <td>в</td>\n",
       "      <td>в</td>\n",
       "      <td>в</td>\n",
       "      <td>в</td>\n",
       "      <td>в</td>\n",
       "      <td>в</td>\n",
       "      <td>в</td>\n",
       "      <td>в</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>2587</td>\n",
       "      <td>настоящее</td>\n",
       "      <td>настоящий</td>\n",
       "      <td>настоящее</td>\n",
       "      <td>настоящее</td>\n",
       "      <td>настоящее</td>\n",
       "      <td>настоящее</td>\n",
       "      <td>настоящий</td>\n",
       "      <td>настоящий</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>2588</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>путешествие</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         text standart_text tokenized_text maru_rnn_lemmatize  \\\n",
       "2014   2573           Но            но             но                 но   \n",
       "2015   2574        самым         самый          самым              самый   \n",
       "2016   2575     надежным      надёжный       надежным           надёжный   \n",
       "2017   2576     способом        способ       способом             способ   \n",
       "2018   2577      пустить       пустить        пустить            пустить   \n",
       "2019   2578          под           под            под                под   \n",
       "2020   2579        откос         откос          откос              откос   \n",
       "2021   2580      дневной       дневной        дневной            дневной   \n",
       "2022   2581   распорядок    распорядок     распорядок         распорядок   \n",
       "2023   2582         было          быть           было               быть   \n",
       "2024   2583   превратить    превратить     превратить         превратить   \n",
       "2025   2584     утреннюю      утренний       утреннюю           утренний   \n",
       "2026   2585     прогулку      прогулка       прогулку           прогулка   \n",
       "2027   2586            в             в              в                  в   \n",
       "2028   2587    настоящее     настоящий      настоящее          настоящее   \n",
       "2029   2588  путешествие   путешествие    путешествие        путешествие   \n",
       "\n",
       "     wordnet_lemmatize pymorphy_lemmatize mystem_lemmatize  \\\n",
       "2014                но                 но               но   \n",
       "2015             самым              самый            самый   \n",
       "2016          надежным           надёжный         надежный   \n",
       "2017          способом             способ           способ   \n",
       "2018           пустить            пустить          пускать   \n",
       "2019               под                под              под   \n",
       "2020             откос              откос            откос   \n",
       "2021           дневной            дневный          дневной   \n",
       "2022        распорядок         распорядок       распорядок   \n",
       "2023              было               быть             быть   \n",
       "2024        превратить         превратить       превращать   \n",
       "2025          утреннюю           утренний         утренний   \n",
       "2026          прогулку           прогулка         прогулка   \n",
       "2027                 в                  в                в   \n",
       "2028         настоящее          настоящее        настоящий   \n",
       "2029       путешествие        путешествие      путешествие   \n",
       "\n",
       "     mystem_lemmatize_sents  \n",
       "2014                     но  \n",
       "2015                  самый  \n",
       "2016               надежный  \n",
       "2017                 способ  \n",
       "2018                пускать  \n",
       "2019                    под  \n",
       "2020                  откос  \n",
       "2021                дневной  \n",
       "2022             распорядок  \n",
       "2023                   быть  \n",
       "2024             превращать  \n",
       "2025               утренний  \n",
       "2026               прогулка  \n",
       "2027                      в  \n",
       "2028              настоящий  \n",
       "2029            путешествие  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standart[2014:2030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
